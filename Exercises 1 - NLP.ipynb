{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk # https://www.nltk.org/install.html  \n",
    "import numpy # https://www.scipy.org/install.html  \n",
    "import matplotlib.pyplot # https://matplotlib.org/downloads.html  \n",
    "\n",
    "#You also need to run nltk.download() in order to download NLTK before proceeding:\n",
    "#nltk.download()\n",
    "from nltk.book import *\n",
    "# could also be\n",
    "# from nltk.corpus import brown\n",
    "# brown.words()\n",
    "\n",
    "# I run the code underneath to get output for all code and not just the last line\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Part I:\n",
    "\n",
    "☼ Try using the Python interpreter as a calculator, and typing expressions like 12 / (4 + 1).\n",
    "\n",
    "☼ Given an alphabet of 26 letters, there are 26 to the power 10, or 26 ** 10, ten-letter strings we can form. That works out to 141167095653376. How many hundred-letter strings are possible?\n",
    "\n",
    "☼ The Python multiplication operation can be applied to lists. What happens when you type ['Monty', 'Python'] * 20, or 3 * sent1?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1) \n",
    "12 / (4 + 1)\n",
    "# 1.2) \n",
    "26**10\n",
    "# 1.2) \n",
    "26**100\n",
    "# 1.3) \n",
    "['Monty', 'Python'] * 20\n",
    "LOL = ('Mony', 'Python')\n",
    "3 * LOL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Part II:\n",
    "\n",
    "☼ Review 1 on computing with language. How many words are there in text2? How many distinct words are there?\n",
    "\n",
    "☼ Compare the lexical diversity scores for humor and romance fiction in 1.1. Which genre is more lexically diverse?\n",
    "\n",
    "☼ Produce a dispersion plot of the four main protagonists in Sense and Sensibility: Elinor, Marianne, Edward, and Willoughby. What can you observe about the different roles played by the males and females in this novel? Can you identify the couples?\n",
    "\n",
    "☼ Find the collocations in text5.\n",
    "\n",
    "☼ Consider the following Python expression: len(set(text4)). State the purpose of this expression. Describe the two steps involved in performing this computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1, first total number of tokens, then the total number of words, and then the number of unique words:\n",
    "len(text2) # 141576 tokens in total (signs, words, entities of strings in the text, e.g. \"mom\", \"?\", \",\", \".\", \"--\")\n",
    "words_t2 = [w for w in text2 if w.isalpha() == True] # looping though the list to get the number of words - that is without any signs \n",
    "len(words_t2) # 120733 total number of words (sings excluded)\n",
    "# list(words_t2) # list of all the words in the text (excluding signs)\n",
    "\n",
    "#set(words_t2) # list/presentation of distrinct words / vocabulary\n",
    "#sorted(set(words_t2)) # the alphabetically sorted different words / vocabulary \n",
    "len(set(words_t2))# 6833 unique words - length/number of unique words \n",
    "\n",
    "#Now, let's calculate a measure of the lexical richness of the text. \n",
    "# The next example shows us that the number of distinct words is just 6% of the total number of words, \n",
    "# or equivalently that each word is used 16 times on average \n",
    "len(set(words_t2)) / len(words_t2) # 0.055602030927749665\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 lexical diversity\n",
    "# lexical diversity \n",
    "# To repeat calculations on several texts, without retyping a formula, you can come up with\n",
    "# your own name for a task, like \"lexical_diversity\" or \"percentage\", \n",
    "# and associate it with a block of code. Now you only have to type a short name instead of\n",
    "# one or more complete lines of Python code, and you can re-use it as often as you like. \n",
    "# The block of code that does a task for us is called a function, \n",
    "# and we define a short name for our function with the keyword def. \n",
    "\n",
    "# function that calculates lexical diversity \n",
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)\n",
    "# Calculates what percentage of the text is taken up by a specific word\n",
    "def percentage(count, total):\n",
    "    return 100 * count / total\n",
    "    # e.g. percentage(text4.count('a'), len(text4))\n",
    "    \n",
    "# compare lexical diversity between text 2 and text 6 because text 2 is more romance \n",
    "# and text 6 is more humour \n",
    "words_t6 = [w for w in text6 if w.isalpha() == True] # looping though the list to get the number of words - that is without any signs \n",
    "\n",
    "print(lexical_diversity(words_t2)) # 0.055602030927749665\n",
    "print(lexical_diversity(words_t6)) # 0.18427947598253275\n",
    "# this means that the number of distinct words is only used 6% of the total number of words in text 2,\n",
    "# while the number of distinct words is 18%  of the total number of words in thext 6. \n",
    "# Therefore the lexical diversity seems to be grater in the humor text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3 Produce a dispersion plot of the four main protagonists in Sense and Sensibility (text 2): \n",
    "# Elinor, Marianne, Edward, and Willoughby. What can you observe about the different roles\n",
    "# played by the males and females in this novel? Can you identify the couples?\n",
    "text2.dispersion_plot([\"Elinor\", \"Marianne\", \"Edward\", \"Willoughby\"])\n",
    "# example: this function let us see the different contexts in which the word occur\n",
    "#text2.concordance(\"affection\")\n",
    "# this function lets us see the words that appear in a similar range of contexts\n",
    "#text2.similar(\"Elinor\")\n",
    "# The term common_contexts allows us to examine just the contexts that are shared by two \n",
    "# or more words:\n",
    "text2.common_contexts([\"Elinor\", \"Willoughby\"])\n",
    "text2.common_contexts([\"Elinor\", \"Edward\"])\n",
    "text2.common_contexts([\"Marianne\", \"Willoughby\"])\n",
    "text2.common_contexts([\"Marianne\", \"Edward\"])\n",
    "#text2_collocations()\n",
    "fdist2 = FreqDist(text2)\n",
    "fdist2.most_common(50)\n",
    "#new = text2-fdist2\n",
    "# wtf!! new = text2[-fdist2]\n",
    "#[1:9] = ['Second', 'Third'] [2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wanna chat',\n",
       " 'PART JOIN',\n",
       " 'MODE #14-19teens',\n",
       " 'JOIN PART',\n",
       " 'PART PART',\n",
       " 'cute.-ass MP3',\n",
       " 'MP3 player',\n",
       " 'JOIN JOIN',\n",
       " 'times .. .',\n",
       " 'ACTION watches',\n",
       " 'guys wanna',\n",
       " 'song lasts',\n",
       " 'last night',\n",
       " 'ACTION sits',\n",
       " '-...)...- S.M.R.',\n",
       " 'Lime Player',\n",
       " 'Player 12%',\n",
       " 'dont know',\n",
       " 'lez gurls',\n",
       " 'long time']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.4 Find the Collocations in text 5\n",
    "# A collocation is a sequence of words that occur together unusually often. Thus red wine is \n",
    "# a collocation, whereas the wine is not. A characteristic of collocations is that they are\n",
    "# resistant to substitution with words that have similar senses. (bigrams = list of word pairs)\n",
    "# collocations are essentially just frequent bigrams, except that we want to pay more attention \n",
    "# to the cases that involve rare words. In particular, we want to find bigrams that occur more\n",
    "# often than we would expect based on the frequency of the individual words\n",
    "#text4.collocations()\n",
    "text5.collocation_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider the following Python expression: len(set(text4)). State the purpose of this \n",
    "# expression. Describe the two steps involved in performing this computation.\n",
    "unique_words_t4 = set(text4) # # list/presentation of distrinct words / vocabulary\n",
    "len(unique_words_t4)# 6833 unique words - length/number of unique words \n",
    "#sorted(set(text4)) # the alphabetically sorted different words / vocabulary \n",
    "# len(set(text4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Part III:\n",
    "\n",
    "☼ Review 2 on lists and strings.\n",
    "\n",
    "Define a string and assign it to a variable, e.g., my_string = 'My String' (but put something more interesting in the string). Print the contents of this variable in two ways, first by simply typing the variable name and pressing enter, then by using the print statement.\n",
    "Try adding the string to itself using my_string + my_string, or multiplying it by a number, e.g., my_string * 3. Notice that the strings are joined together without any spaces. How could you fix this?    \n",
    "\n",
    "☼ Define a variable my_sent to be a list of words, using the syntax my_sent = [\"My\", \"sent\"] (but with your own words, or a favorite saying).\n",
    "Use ' '.join(my_sent) to convert this into a string.\n",
    "Use split() to split the string back into the list form you had to start with.    \n",
    "\n",
    "☼ Define several variables containing lists of words, e.g., phrase1, phrase2, and so on. Join them together in various combinations (using the plus operator) to form whole sentences. What is the relationship between len(phrase1 + phrase2) and len(phrase1) + len(phrase2)?\n",
    "\n",
    "☼ Consider the following two expressions, which have the same value. Which one will typically be more relevant in NLP? Why?  \n",
    "- \"Monty Python\"[6:12]\n",
    "- [\"Monty\", \"Python\"][1]\n",
    "\n",
    "☼ We have seen how to represent a sentence as a list of words, where each word is a sequence of characters. What does sent1[2][2] do? Why? Experiment with other index values.\n",
    "\n",
    "☼ The first sentence of text3 is provided to you in the variable sent3. The index of the in sent3 is 1, because sent3[1] gives us 'the'. What are the indexes of the two other occurrences of this word in sent3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 string\n",
    "my_string = \"birthday\"\n",
    "my_string\n",
    "print(my_string)\n",
    "my_string + my_string\n",
    "my_string*3\n",
    "# how can we make space between the birthday words? \n",
    "# adding a space in the orignial string?\n",
    "my_string = my_string + \" \"\n",
    "my_string*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 variable \n",
    "#my_sent = [\"That\", \"was\", \"an\", \"amazing\", \"weekend\"]\n",
    "# Use ' '.join(my_sent) to convert this into a string\n",
    "new_my_sent = ' '.join(my_sent)\n",
    "# Use split() to split the string back into the list form you had to start with\n",
    "new_my_sent.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 \n",
    "phrase1 = \"This is a good view \"\n",
    "phrase2 = \"and the weather is so nice\"\n",
    "phrase1 + phrase2\n",
    "len(phrase1 + phrase2) \n",
    "len(phrase1) + len(phrase2)\n",
    "# same result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 \n",
    "# Consider the following two expressions which have the same value\n",
    "# Which one will typically be more relevant in NLP? Why?\n",
    "\"Monty Python\"[6:12]\n",
    "[\"Monty\", \"Python\"][1]\n",
    "# second? beacuse we mostly work with lists or sets of words and acces them through indexing, \n",
    "# instead of working with strings??? I don't know :D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5\n",
    "# We have seen how to represent a sentence as a list of words, where each word is a sequence of characters. \n",
    "# What does sent1[2][2] do? Why? Experiment with other index values.\n",
    "sent1[2][2] # this indexing accesses the 3rd word in the list, and the 3rd letter in that word\n",
    "sent1[2]\n",
    "sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'the',\n",
       " 'beginning',\n",
       " 'God',\n",
       " 'created',\n",
       " 'the',\n",
       " 'heaven',\n",
       " 'and',\n",
       " 'the',\n",
       " 'earth',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[1, 5, 8]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.6\n",
    "# The first sentence of text3 is provided to you in the variable sent3.\n",
    "# The index of the in sent3 is 1, because sent3[1] gives us 'the'. \n",
    "# What are the indexes of the two other occurrences of this word in sent3?\n",
    "sent3\n",
    "\n",
    "sent3.index('the') # GIVER KUN DEN FØRSTE OCCURENCE\n",
    "sent3_the = [i for i, x in enumerate(sent3) if x == \"the\"]\n",
    "sent3_the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Part V:\n",
    "\n",
    "◑ Review the discussion of looping with conditions in 4. Use a combination of for and if statements to loop over the words of the movie script for Monty Python and the Holy Grail (text6) and print all the uppercase words, one per line.\n",
    "\n",
    "◑ Write expressions for finding all words in text6 that meet the conditions listed below. The result should be in the form of a list of words: ['word1', 'word2', ...].\n",
    "\n",
    "Ending in ise\n",
    "Containing the letter z\n",
    "Containing the sequence of letters pt\n",
    "Having all lowercase letters except for an initial capital (i.e., titlecase)  \n",
    "◑ Define sent to be the list of words ['she', 'sells', 'sea', 'shells', 'by', 'the', 'sea', 'shore']. Now write code to perform the following tasks:\n",
    "\n",
    "Print all words beginning with sh\n",
    "Print all words longer than four characters  \n",
    "◑ What does the following Python code do?  sum(len(w) for w in text1) Can you use it to work out the average word length of a text?\n",
    "\n",
    "◑ Define a function called vocab_size(text) that has a single parameter for the text, and which returns the vocabulary size of the text.\n",
    "\n",
    "◑ Define a function percent(word, text) that calculates how often a given word occurs in a text, and expresses the result as a percentage.\n",
    "\n",
    "◑ We have been using sets to store vocabularies. Try the following Python expression: set(sent3) < set(text1). Experiment with this using different arguments to set(). What does it do? Can you think of a practical application for this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1772"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.1 \n",
    "# Review the discussion of looping with conditions in 4. Use a combination of for and if \n",
    "# statements to loop over he words of the movie script for Monty Python and the \n",
    "# Holy Grail (text6) and print all the uppercase words, one per line.\n",
    "# from the book ch. 4.1\n",
    "\n",
    "upper_words = [w for w in text6 if w.isupper() == True]\n",
    "len(upper_words)\n",
    "\n",
    "#sent7\n",
    "#[w for w in sent7 if len(w) < 4]\n",
    "#[w for w in sent7 if len(w) <= 4]\n",
    "#[w for w in sent7 if len(w) == 4]\n",
    "#[w for w in sent7 if len(w) != 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor w in text6:\\n    if w.endswith(\\'ise\\'):\\n        print(w, end = \", \")\\n    elif \\'z\\' in w: \\n        print(w, end = \", \")\\n    elif \\'pt\\' in w: \\n        print(w, end = \", \")\\n    elif w.istitle():\\n        print(w, end = \", \")\\n'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\"\\nwords_52 = []\\nfor w in text6:\\n    if w.endswith('ise'):\\n        words_52.append(w)\\n    elif 'z' in w: \\n        words_52.append(w)\\n    elif 'pt' in w: \\n        words_52.append(w)\\n    elif w.istitle():\\n        words_52.append(w)\\n#print(words_52)\\n\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.2\n",
    "# Write expressions for finding all words in text6 that meet the conditions listed below. \n",
    "# The result should be in the form of a list of words: ['word1', 'word2', ...].\n",
    "# Ending in ise \n",
    "# Containing the letter z \n",
    "# Containing the sequence of letters pt \n",
    "# Having all lowercase letters except for an initial capital (i.e., titlecase)\n",
    "\"\"\"\n",
    "for w in text6:\n",
    "    if w.endswith('ise'):\n",
    "        print(w, end = \", \")\n",
    "    elif 'z' in w: \n",
    "        print(w, end = \", \")\n",
    "    elif 'pt' in w: \n",
    "        print(w, end = \", \")\n",
    "    elif w.istitle():\n",
    "        print(w, end = \", \")\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "words_52 = []\n",
    "for w in text6:\n",
    "    if w.endswith('ise'):\n",
    "        words_52.append(w)\n",
    "    elif 'z' in w: \n",
    "        words_52.append(w)\n",
    "    elif 'pt' in w: \n",
    "        words_52.append(w)\n",
    "    elif w.istitle():\n",
    "        words_52.append(w)\n",
    "#print(words_52)\n",
    "\"\"\"\n",
    "wor = []\n",
    "for w in text6:\n",
    "    if w.endswith('ise') and 'z' in w and 'pt' in w and w.istitle():\n",
    "        wor.append(w)\n",
    "print(wor)\n",
    "len(wor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['she', 'sells', 'shells', 'shore']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "999044"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3.830411128023649"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.3\n",
    "sent = ['she', 'sells', 'sea', 'shells', 'by', 'the', 'sea', 'shore']\n",
    "# Print all words beginning with sh \n",
    "# Print all words longer than four characters\n",
    "words_53 = []\n",
    "for w in sent:\n",
    "    if w.startswith('sh'):\n",
    "        words_53.append(w)\n",
    "    elif len(w) > 4: \n",
    "        words_53.append(w)   \n",
    "print(words_53)\n",
    "\n",
    "# 5.4 - what does the code do\n",
    "sum(len(w) for w in text1) # makes a list with the length of each word in text1 and \n",
    "# sums the total of all these numbers AKA gives the total number of characters \n",
    "# (signs and letters) in text1\n",
    "# Can you use it to work out the average word length of a text?\n",
    "sum(len(w) for w in text1)/len(text1) # average word length is 3.8 characters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15323863971238286"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "260819"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.5\n",
    "# Define a function called vocab_size(text) \n",
    "#that has a single parameter for the text, \n",
    "#and which returns the vocabulary size of the text.\n",
    "\n",
    "def vocab_size(text):\n",
    "  return len(set(text))\n",
    "\n",
    "#vocab_size(text1)\n",
    "\n",
    "# 5.6  Define a function percent(word, text) that calculates how often a given word occurs\n",
    "# in a text, and expresses the result as a percentage.\n",
    "def percent(word, text):\n",
    "  return text.count(word) / len(text)*100\n",
    "\n",
    "percent('Hello', text6)\n",
    "\n",
    "# 5.7\n",
    "# We have been using sets to store vocabularies. \n",
    "# Try the following Python expression: set(sent3) < set(text1). \n",
    "# Experiment with this using different arguments to set(). \n",
    "# What does it do? Can you think of a practical application for this?\n",
    "set(sent3) < set(text1) # checks if the statement is true \n",
    "# Can compare the vocabulary of different texts???\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Extra:\n",
    "\n",
    "If you've been through all the exercises, here are 2 retro-engineering tasks:\n",
    "\n",
    "- Create a *homemade_bigrams* function that takes as input a tokenized text and outputs a list of bigrams (2 words combinations in text). Can you extend it to n-grams?\n",
    "\n",
    "- Create a *FrequencyDistribution* class similar to the FreqDist class object in the NLTK package. (Don't check the original code!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homemade_bigrams(tokenized_text):\n",
    "    return list(bigrams(tokenized_text))\n",
    "\n",
    "token_text2 = [w for w in text2 if w.isalpha() == True]\n",
    "\n",
    "homemade_bigrams(token_text2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FrequencyDistribution(text, number): \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleantext2 =[w for w in text2 if w.isaphla()]\n",
    "#cleantext2 = []\n",
    "#for w in text2: \n",
    "  #  if w.isaplha():\n",
    "   #     cleantext2.append(w)\n",
    "        \n",
    "\n",
    "# you can index from strings\n",
    "# string1 = \"nice\"\n",
    "#string1[0] = \"?\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
